---
title: "Project 2"
description: |
  Coffee Review Visualizations
author:
- first_name: "AASHUTOSH"
  last_name: "SEHGAL (0780170)"
- first_name: "IMAN"
  last_name: "FATIMA (0784241)"
- first_name: "JASMINE (0775648)"
- first_name: "RUBALDEEP"
  last_name: "KAUR (0775850)"
- first_name: "UMAIR"
  last_name: "NABEEL (0780185)"

output: distill::distill_article

---
**Group Number: 25**

**We, Aashutosh Sehgal, Iman Fatima, Jasmine, Rubaldeep Kaur and Umair Nabeel, hereby state that we have not communicated with or gained** **information in any way from any person or resource that would violate the College’s academic integrity policies, and that all work **
**presented is our own. In addition, we also agree not to share our work in any way, before or after submission, that would violate the**
**College’s academic integrity policies.**

**R & RStudio Version:** 

- 4.0.5 (2021-03-31)
- 1.4.1106

**Packages and their versions:**

- Tidyverse (1.3.1)
- Ggplot2 (3.3.3)
- Skimr (2.1.3)
- Patchwork (1.1.1)
- Pander (0.6.4)
- GGridges (0.5.3)
- Viridis (0.6.1)
- Hrbrthemes (0.8.0)
- RColorBrewer (1.1.2)

# NOTE

### The plots have been arranged in alphabetical order of authors names for both Univariate and Bivariate. 

# Loading Data 

```{r message=FALSE}
library(tidyverse)
library(patchwork)
library(pander)
library(ggridges)
library(viridis)
library(hrbrthemes)
library(RColorBrewer)

coffee_ratings <- readr::read_csv(
  'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv'
  )
```

```{r}
library(skimr)

skim(coffee_ratings)
```

# Univariate Analysis

### For numeric variable, we will be using Aroma Grading of Coffee:

1. To visualize the distribution of Aroma grading, we will use histogram.

```{r message=FALSE}
ggplot(coffee_ratings) +
  geom_histogram(mapping = aes(aroma),fill="orange") +
  labs(x="Aroma grading",y="Count",title= "Distribution of Aroma Grading") +
  theme_minimal()
```

2. To look at any outliers present in the data, I used boxplot.  

```{r}
ggplot(coffee_ratings) +
  geom_boxplot(aes(aroma),fill="Pink") +
  labs(x="Aroma grading",title= "Boxplot of Aroma Grading") +
  theme_minimal()
```

```{r message=FALSE}
coffee_ratings %>% filter(aroma < 6.25)
``` 

We consider these 3 as outliers as for bismarck castro's arabica bean has 0.00 Total Cup Points and all 3 of them have category 2 defect along with low aroma grade. 

To remove these outliers:

```{r}
coffee_ratings_without_aroma_outliers <- coffee_ratings %>% filter(aroma>6.25) 
```

3. The shape of plot is Unimodal and we can see that the plot is Left skewed.

4. We can observe the mean and median of aroma grading before and after removing outliers:

*BEFORE*

```{r}
coffee_ratings %>% summarise(mean_aroma=mean(aroma),median_aroma=median(aroma))
```

*AFTER*

```{r}
coffee_ratings_without_aroma_outliers %>% summarise(mean_aroma=mean(aroma),median_aroma=median(aroma))
```

```{r message=FALSE}
ggplot(coffee_ratings_without_aroma_outliers) +
  geom_histogram(mapping = aes(aroma),fill="green") +
  geom_vline(mapping = aes(xintercept=median(aroma)),size=1.5,linetype="dashed") +
  geom_text(aes(x=median(aroma),y=100),label= "\nMedian", text=element_text(size=11)) +
  labs(x="Aroma grading",y="Count",title= "Distribution of Aroma Grading Without Outliers") +
  theme_minimal()
```

As we can see that just by removing the outliers the mean and median have came close and, we can get an almost symmetric plot which is close to normal distribution, therefore no further transformation is required.

5. 

*WITH OUTLIERS "MEAN, MEDIAN, STANDARD DEVIATION, IQR"*

```{r}
coffee_ratings %>% summarise(mean_aroma=mean(aroma),median_aroma=median(aroma),sd_aroma=sd(aroma),IQR_aroma=IQR(aroma))
```

*WITHOUT OUTLIERS "MEAN, MEDIAN, STANDARD DEVIATION, IQR"*

```{r}
coffee_ratings_without_aroma_outliers %>%
  summarise(
    mean_aroma=mean(aroma),median_aroma=median(aroma),sd_aroma=sd(aroma),IQR_aroma=IQR(aroma)
    )
```

6. From the above Quantitative Analysis we observe that, the data without outliers does not have much difference between "Mean" and "Median" thus we can use either of them, but if we use original data with outliers it would be better to use "Median" is more robust as compared to "Mean".

7. From the above Quantitative Analysis we observe that, the data without outliers does not have much difference between "Standard Deviation" and "IQR" thus we can use either of them, but if we use original data with outliers it would be better to use "IQR" is more robust as compared to "Standard Deviation".

## Selecting Variables

```{r}
coffee<- coffee_ratings %>% select(total_cup_points,
species,
country_of_origin,
number_of_bags,
variety,
processing_method,
flavor,
uniformity,
category_one_defects
)
```

### Continuous/Numerical variable: flavor

The score given for flavor account for the intensity, quality and complexity of its combined taste and aroma, experienced when the coffee is slurped into the mouth vigorously so as to involve the entire palate in the evaluation.

Using the glimpse function

```{r}
glimpse(coffee$country_of_origin)
```

We can see that country is a numerical variable with 1339 values.

A quick summary of the statistics using skimr package

```{r}
skim(coffee$flavor)
```

There are no missing values for this variable and we can plot a histogram to check the distribution of values.

```{r}
ggplot(coffee)+
  geom_histogram(aes(flavor),color='red',fill='skyblue')+
  labs(title="Distribution of flavor")+
  theme_minimal()
```

The distribution is highly right-skewed. By increasing the number of bins, we can see that distribution is also unimodal. There is only one peak and there are also some outliers, some values that have 0 value. 

```{r}
ggplot(coffee)+
  geom_histogram(aes(flavor),bins=100,color='red',fill='skyblue')+
  labs(title="Distribution of flavor with 100 bins")+
  theme_minimal()
```

### Handling outliers

We can filter out the rows that have 0 values

```{r}
coffee %>% filter(flavor==0) 
```

This row has 0 value for flavor and some other variables are also zero so we can assume it an entry error.We can remove this row by using

```{r}
coffee<-coffee[coffee$flavor!=0,]
```

Now again plotting the histogram after removing the outliers and increasing the number of bins to 35, we have an approximate symmetric distribution  

```{r}
ggplot(coffee)+
  geom_histogram(aes(flavor),bins=35,color='red',fill='skyblue')+
  labs(title="Distribution of flavor")+
  theme_minimal()
```

```{r, echo=FALSE}
p<-ggplot(coffee)+
  geom_histogram(aes(flavor),bins=35,color='red',fill='skyblue')+
  labs(title="Distribution of flavor")+
  theme_minimal()
```

Since we already have a distribution that is pretty close to normal distribution, we don't need to apply a transformation function such as log etc.

### Central tendency

Since flavor variable is not extremely skewed, mean is a very good measure of central tendency

```{r}
mean(coffee$flavor)
```

### Plotting the mean

```{r}
p+geom_vline(aes(xintercept=mean(flavor)),
            color="blue", linetype="dashed", size=1)
```

### Spread using Standard Deviation

```{r}
sd(coffee$flavor)
```

We can see that most of our data values can fit within 3 standard deviations of the mean.

### For numeric variable I will be using aftertaste Grading of Coffee:

```{r}
skim(coffee_ratings$aftertaste)
```

### Distribution of aftertaste

```{r}
ggplot(coffee_ratings)+
  geom_histogram(aes(aftertaste),color='blue',fill='pink', bins = 30, binwidth = 0.2)+
  labs(title="Distribution of aftertaste")+
  theme_minimal()
```

As we can see that all the values are distributed within the range of 5.5 to 8.5.

### To look at any outliers present in the data, I used boxplot.

```{r}

ggplot(coffee_ratings) +
  geom_boxplot(aes(aftertaste),fill="Pink") +
  labs(x="Aftertaste grading",title= "Boxplot of Aftertaste Grading") +
  theme_minimal()
```

### This bit of the code creates a summary table that provides the min/max and inter-quartile range.

```{r}

coffee_ratings %>%
  summarise(Min = min(aftertaste),
            Max = max(aftertaste),
            Median = median(aftertaste),
            IQRange = IQR(aftertaste))
```

It is also possible to extract the values of the potential outliers based on the IQR criterion using the boxplot.stats()$out function:

```{r}
boxplot.stats(coffee_ratings$aftertaste)$out
```

Extracting all the rows corresponding to these outliers:

```{r}
out <- boxplot.stats(coffee_ratings$aftertaste)$out
out_ind <- which(coffee_ratings$aftertaste %in% c(out))
coffee_ratings[out_ind,]  
```

### Let's add the mean of aftertaste to plot.

```{r}
coffee_ratings %>%
ggplot(aes(aftertaste)) +
    geom_histogram(binwidth = 0.2, color = "blue",fill = "pink", bins = 35) +
    geom_vline(xintercept = mean(coffee_ratings$aftertaste), lwd = 1, color= "blue", linetype="dotted"  ) +
    labs(title = "Distribution of Aftertaste",
         x = "After taste grade",
         y = "Count") +
  theme_minimal()
```

### For numeric variable I will be using Acidity Grading of Coffee:

1. To visualize the distribution of Acidity grading I will use histogram.

```{r}
skim(coffee_ratings$acidity)
```

```{r message=FALSE}
ggplot(coffee_ratings) +
  geom_histogram(mapping = aes(acidity), color='black',fill="brown") +
  labs(x="Acidity grading",y="Count",title = "Distribution of acidity") +
  theme_minimal()
```

- As the plot depicts that all the values are distributed between the range of 5.0 to 8.0

### To look at any outliers present in the data, I used boxplot.

```{r}
ggplot(coffee_ratings,
       aes(acidity)) +
  geom_boxplot (bins = 10,color='black',fill='brown') +
    labs(title = "Distribution of acidity",
         x = "After acidity grade",
         y = "Count") +
  theme_minimal()
```

```{r message=FALSE}
coffee_ratings %>%
  summarise(Min = min(aftertaste),
            Max = max(aftertaste),
            Median = median(aftertaste),
            IQRange = IQR(aftertaste))
``` 

4. We can also extract the values of outliers by using the boxplot.ststs()out function

```{r}
boxplot.stats(coffee_ratings$acidity)$out
```

```{r}
out <- boxplot.stats(coffee_ratings$acidity)$out
out_ind <- which(coffee_ratings$acidity %in% c(out))
coffee_ratings[out_ind,] 
```

### Now I am adding Mean 

```{r}
coffee_ratings %>%
ggplot(aes(acidity)) +
    geom_histogram(binwidth = 0.30, color = "black",fill = "brown", bins = 35) +
    geom_vline(xintercept = mean(coffee_ratings$acidity), lwd = 1, color= "black", linetype="dotted"  ) +
    labs(title = "Distribution of Acidity",
         x = "Acidity grade",
         y = "Count") +
  theme_minimal()
```

1. For first univariate analysis I am using body variable

```{r message=FALSE,warning=FALSE,code_folding=TRUE}
plt1 <- ggplot(data = coffee_ratings, 
       aes(body))+
  geom_histogram(bins=50,fill="blue",alpha=0.5,show.legend = FALSE) +ylab("Frequency") +xlab("")+
  labs(title = "Distribution of body grading")

plt2 <- ggplot(coffee_ratings,aes(body),color =  "blue")+
  geom_boxplot(fill  ="blue",alpha = 0.5) +  xlab("Body Grading") +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

plt1 + plt2 + plot_layout(nrow = 2, heights = c(6, 1))
```

2. As can be seen from the box plot there are outliers below 6 and now we will filter out outliers

```{r}
coffee_ratings %>% filter(body < 6)
```

We will consider these 4 as outliers as bismark castro has zero total cup points and other three have very low  body grade points.

3. To remove the outliers in body variable:

```{r}
coffee_ratings_Body_outliers_removed <- coffee_ratings %>% filter(body > 6)
```

4. Plotting the graph after removing outliers

```{r}
 coffee_ratings_Body_outliers_removed %>% ggplot(aes(body)) +
  geom_histogram(aes(y=..density..),fill="#375E97",alpha=0.5) +
  geom_density(col="#FFBB00",size=1.5) +
  labs(x="Body grading",y="Frequency",title = "Distribution of body grading")
```

> As can be seen from the graph that it has one peak so the plot is unimodal  and no visible skewness is there which indicates that the graph is somewhat bell curved and also simialr to normal distribution.  

5. Checking change in mean and median before and after removing outliers

### BEFORE

```{r}
coffee_ratings %>%
    summarize(variable = "body",mean_body = mean(body), median_body = median(body)) %>% 
    pander()
```

### AFTER

```{r}
coffee_ratings_Body_outliers_removed %>%
    summarize(variable = "body",mean_body = mean(body), median_body = median(body)) %>% 
    pander()
```

As can been seen by removing the outliers the mean have increased abd is now closer to median than before.

6. Now we will check change in 20%,40%,60% and 80% quantiles before and after removing outliers

### Before

```{r}
coffee_ratings %>%
    summarize(variable = "body",
              sd_body = sd(body),
              q0.2 = quantile(body, 0.2),
              q0.4 = quantile(body, 0.4),
              q0.6 = quantile(body, 0.6),
              q0.8 = quantile(body, 0.8),
              IQR_body = IQR(body)) %>%
    pander

```

### After

```{r}

coffee_ratings_Body_outliers_removed %>%
    summarize(variable = "body",
              sd_body = sd(body),
              q0.2 = quantile(body, 0.2),
              q0.4 = quantile(body, 0.4),
              q0.6 = quantile(body, 0.6),
              q0.8 = quantile(body, 0.8),
              IQR_body = IQR(body)) %>%
    pander
```

7. From the above quantitative analysis we can see that after removing outliers the standard deviation of the variable body have decreased but there is no change in different quantile and simultaneously in IQR.

### For categorical variable, I will be using Owner:

```{r}
coffee_ratings_owner <- coffee_ratings %>%
  filter(total_cup_points != 0) %>%
  mutate(owner = str_replace_all(owner, "[^a-zA-Z0-9 ]", ""),
         owner = str_trim(owner))
coffee_ratings_clean_owner <- coffee_ratings_owner %>% drop_na(owner)
coffeee_ratings_clean_owner <- coffee_ratings_clean_owner %>% group_by(owner) %>% count(owner,sort = TRUE)
coffee_ratings_clean_owner <- head(coffeee_ratings_clean_owner,10)
```

1. To visualize the distribution of counts for this variable, a bar chart would seem appropriate.

```{r}
ggplot(coffee_ratings_clean_owner,aes(owner,n)) +
  geom_bar(stat = 'identity',fill="purple") +
  geom_text(aes(label=n,hjust=0.1)) +
  labs(x="Name of Owners",y="Count",title= "Top 10 Owners") +
  theme_minimal() +
  coord_flip()
```

2. To visualize the distribution of proportions for this variable, I would use another bar chart.

```{r}
sum <- sum(coffee_ratings_clean_owner$n)
coffee_ratings_clean_owner <-coffee_ratings_clean_owner %>% mutate(x=n/sum)
ggplot(coffee_ratings_clean_owner,aes(owner,x)) +
  geom_bar(stat='identity',fill="lightblue") +
  geom_text(aes(label=round(x,2),hjust=0.25)) +
  labs(x="Name of Owners",y="Proportion",title= "Top 10 Owners") +
  theme_minimal() +
  coord_flip()
```

3. There were some NA values and abnormal characters in owner's names which were the unusual observations and were removed using "drop_na()" and regular expression "[^a-zA-Z0-9]" i.e. from a-z, A-Z, 0-9 only.

4. There are 315 unique values values for color after removing NA nut to illustrate meaningful information we will use only To 10 most frequently occuring owners and they are as follow:

```{r}
unique(coffee_ratings_clean_owner$owner)
```

### First variable I am using for univariate analysis is country_of_origin which is the country where the coffee is from.

### Categorical variable: country_of_origin

Using the glimpse function

```{r}
glimpse(coffee$country_of_origin)

```

We can see that country is a categorical variable with 1339 values

### Bar chart

Mexico is the country where most of the coffee comes from.

```{r}
ggplot(coffee)+
  geom_bar(aes(country_of_origin))+
  labs(title="Count of Countries",x="Count",y="Country")+
  coord_flip()+
  theme_minimal()
```

### Proportion table

I have shown the distribution of countries in this variable by proportion which also confirms that Mexico indeed has the biggest proportion out of all countries, followed by Colombia and Guatemala.

```{r}
sort(round(proportions(table(coffee$country_of_origin)),2),decreasing=TRUE)
```

No unusual behavior has been detected in this variable and it works as expected.

We can use the skimr package to check for empty values and we can see that are 36 unique countries and only one NA value.

```{r}
skim(coffee$country_of_origin)
```

### For categorical variable, I will be using Producers:

###  Top 10 Producers of coffee

```{r}
glimpse(coffee_ratings$producer)
```

Frequency table for Producers

```{r}
coffee_producers<- as.data.frame(sort(table(grep('^[A-Za-z ]+$', coffee_ratings$producer, value = TRUE))),decreasing = TRUE)
colnames(coffee_producers)<-c('producers', 'count')
tibble(coffee_producers) 
```

1. To visualize the distribution of counts for this variable, a bar chart would seem appropriate.

```{r}
top_producers<-as.data.frame(tail(coffee_producers,10))

ggplot(data = top_producers, mapping = aes(producers,count))+
  geom_bar(stat = 'identity',fill='pink',color = 'blue')+
  labs(title = "Top 10 producers of Coffee")+
  xlab("Producer")+
  ylab("Count")+
  coord_flip()+
  theme_minimal()
```

2. It is clear from the plot that maximum coffee is produced by La Plata.<br>

3. There were some abnormal characters in Producers names which were the unusual observations and were removed using “^[A-Za-z ]+$” i.e. from a-z, A-Z only.<br>

4. There are 429 unique values for producers. In order to illustrate meaningful information we will be using only To 10 most frequently occurring Producers and they are as follow:

```{r}
top_producers<-as.data.frame(tail(coffee_producers,10))
top_producers
```

5. To visualize the distribution of proportions for this variable, I would use another bar chart.

```{r}
sum <- sum(top_producers$count)

top_producers <-top_producers %>% mutate(x=count/sum)
ggplot(top_producers,aes(producers,x)) +
  geom_bar(stat='identity',fill="purple") +
  labs(x="Name of Producers",y="Proportion",title= "Top 10 Producers") +
  theme_minimal() +
  coord_flip()
```

### For categorical variable, I will be using Variety:

```{r}
unique(coffee_ratings$variety)
```

```{r}
tab<- data.frame(table(coffee_ratings$variety))
colnames(tab)<- c('variety','count')
tab
```

1. To visualize the distribution of counts for this variable, a bar chart would seem appropriate.

```{r}
ggplot(data = drop_na(tab),mapping = aes(variety,count))+
  geom_bar(fill = 'skyblue', stat = 'identity')+
  coord_flip()
```

Among all the top varieties of coffee beans the Caturra is on the top out of all followed by Typica and Bourbon. 

1. For this we are using processing method that is used by companies to process coffee beans.

```{r}
unique(coffee_ratings$processing_method)
```

As we can see there are six categories in processsing method variable

2. Now We will plot these using bar graph to understand the frequency in each category 

```{r}
processing_method_table<-coffee_ratings %>% count(processing_method = factor(processing_method))

ggplot(processing_method_table,aes(x = processing_method,y = n, fill = n))+
  geom_bar(stat="identity")+
  labs(title="Count of Countries",x="Count",y="Country")+
  coord_flip()+geom_text(aes(label = n),size = 2.5,color = "white",hjust = 1.3)+
 scale_fill_gradient(low="darkkhaki", high="darkgreen")+
  labs(x ="Frequency" , y = "Processing Method",title = "Distribution of processing method")
```

3. Now we will be checking the frequency and relative frequency of each category in processing method.

```{r}
coffee_ratings %>%
    group_by(processing_method) %>%
    summarize(frequency = n()) %>%
    arrange(desc(frequency)) %>%
    mutate(relative_frequency = frequency/sum(frequency)) %>%
    pander
```

4. Removing NA's

```{r}
coffee_ratings_no_missing <- coffee_ratings %>% drop_na(processing_method)
```

5. Visualizing the proportion of processing methods

```{r}
ggplot(coffee_ratings_no_missing) +
  geom_bar(aes(x= processing_method,y=..prop..,group=1,fill = ..prop..)) +
  coord_flip()+
  scale_fill_viridis(option = "mako")+
  labs(x="Proportion",y="processing method",title= "Proportion of processing method")
```

> washed/wet method of processing coffee beans is used almost 70% of times whereas Pulped natural/honey method of processing is least used. 

# For Bivariate Analysis

### For 2 numerical variables pair, I will use Moisture grade and Balance grade:

1. Scatter plot with smoothing line to visualize the relationship between these two variables. (4 marks)

```{r message=FALSE}
ggplot(coffee_ratings,aes(moisture,balance)) +
  geom_point(shape=21,alpha= 1/3) +
  geom_smooth(method='lm',se=FALSE) +
  labs(x="Moisture Grade",y="Balance Grade",title= "Relationship between Moisture Grade and Balance Grade") +
  theme_minimal()
```

2. There seems to be a negative, linear relationship between Moisture Grade and Balance Grade,but it appears to be somewhat a weak relationship. I would have expected a similar correlation based on general expectations of moisture degrading the balace of seed.

The correlation coefficient is:

```{r}
cor(coffee_ratings$moisture,coffee_ratings$balance)
```

The value of correlation coefficient is on the weaker side and it confirms what we see on the plot. Although weak the relationship does show that, on average, that as moisture grade increase we would expect a decrease in balance grade.

3. The data includes 2 species of coffee beans from different parts of the world, so that will explain the variation in moisture grade as different regions have different climatic effects, since some regions are dry as compared to other regions with more more humidity thus the balance grade of those beans are affected.

4. The variation of balance grade clearly decreases as moisture grade increases.

### Two numerical variables: Uniformity and total_cup_points

Creating a scatter plot between uniformity and the total cup points.total_cup_points variable contains a a rating out of 100 for the coffee beans.

```{r}
ggplot(coffee,aes(uniformity,total_cup_points))+
  geom_point(shape=21)+
  labs(title="Correlation between uniformity & cup points",y="cup points")+
  theme_minimal()
```

We can see that as uniformity increases, total cup points also increase.

Adding a best fit line to the scatter plot, it appears that uniformity has a linear positive relationship with total cup points, meaning the higher the uniformity of flavor, the higher the coffee is rated out of a 100.

```{r}
ggplot(coffee,aes(uniformity,total_cup_points))+
  geom_point(shape=21,alpha=1/3)+
  geom_smooth(method='lm', se=FALSE)+
  labs(title="Correlation between uniformity & cup points",y="cup points")+
  theme_minimal()
```

We can calculate the correlation coefficient to know the strength of this relationship

```{r}
cor(coffee$uniformity,coffee$total_cup_points)
```

It is a fairly strong relationship with 0.5 correlation coefficient.

### For 2 numerical variables pair, I will use Altitude_mean_meters and total_cup_points:

1. Scatter plot with smoothing line to visualize the relationship between these two variables.

```{r}

coffee_ratings %>%
  filter(altitude_mean_meters < 4000, total_cup_points > 0) %>%
  ggplot(aes(x = altitude_mean_meters, y = total_cup_points)) +
  theme_classic()+
  geom_point(colour = "blue", alpha = 0.3, size = 2) +
  geom_smooth(method = "lm",color="red") +
  labs(x = "Mean Altitude (Metres)", y = "Total Cup Points", title = "Relationship between altitude grown and quality of coffee")
```

2. There seems to be a positive, linear relationship between plotted variables,but it appears to be somewhat a weak relationship.

The correlation coefficient is:

```{r}
cor(coffee_ratings$altitude_mean_meters< 4000,coffee_ratings$total_cup_points,use="na.or.complete")
```

The value of correlation coefficient is positive and it confirms what we see on the plot.

3.The variation of Total cup points clearly increases as as the Mean altitude increases.

# For Bivariate Analysis

### For 2 numerical variables pair, I am using Flavor and Aroma

1. Scatter plot with smoothing line to visualize the relationship between these two variables. (4 marks)

```{r message=FALSE}
ggplot(coffee_ratings,aes(flavor,aroma))+
  geom_point(shape=21)+
  geom_smooth()+
  labs(title="Correlation between flavor & aroma",y=" aroma")+
  theme_minimal()
```

2. There is a positive and linear relationship between Flavor and Aroma.

The correlation coefficient is:

```{r}
cor(coffee_ratings$flavor,coffee_ratings$aroma)
```

The value of correlation coefficient is on the stronger side and we can see on the plot.

### For our bivariate analysis of two numerical variables:

We will be using cupper points grade and total cup points. Cupper points indicate 0-10 grade on tasting by producers and buyers around the world to check the quality of a batch of coffee and total cup points indicate 0-100 rating on the basis of different factors. 

```{r}
coffee_ratings %>%
    ggplot(aes(cupper_points, total_cup_points)) +
    geom_point(color = "dodgerblue", alpha = .5) +
    theme_minimal() +
    labs(x="Cupper points grade",y="Total Cup Points(0-100)",title= "Relationship between cupper and points ") +
  geom_jitter(height=0.5, width=0.3,color = "dodgerblue", alpha = .5)+
    geom_smooth(method = "lm", se = F,color = "darkorange2", size = 1.2)
```

> As can be seen there is a positive and linear relationship between two variables.

3. We can now check the pearson correlation coefficient:

```{r}
coffee_ratings %>%
    select(total_cup_points, cupper_points) %>% 
    cor %>% 
    pander
```

> As can be seen by the coefficient there is fairly strong positive correlation.

### For 1 Numerical and 1 Categorical variable pair, I will use Color and Cupper Points:

1. To visualize the relationship between these two variables we will use Boxplot.

```{r}
coffee_ratings_clean_color <- coffee_ratings %>% 
  drop_na(color)
```

```{r}
coffee_ratings_clean_color_median <- coffee_ratings_clean_color %>%
  group_by(color) %>%
  summarise(median=median(cupper_points)) %>%
  ungroup()
```

```{r}
ggplot(coffee_ratings_clean_color)+
  geom_boxplot(mapping = aes(color,cupper_points,color=color),show.legend=FALSE) +
  geom_point(coffee_ratings_clean_color_median,mapping = aes(color,median),color="Red")+
  geom_line(coffee_ratings_clean_color_median,mapping = aes(color,median,group=1))+
  labs(x="Color",y="Cupper Points",title= "Relationship between Color and Cupper Points") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.9))
```

2. It appears that Median of "Cupper Points" is in a weakly linear relation with "Colors" except for "Blue-Green" and "Bluish-Green" which is almost same, however, overall the relationship is negative as we see a downward trend on slope. 

3. In context of data, as different beans come from different countries, regions and are processed differently, thus we are expected to see this kind of fluctuations for various colors of beans, also not so strong relation is expected from a variable such as color of bean as there are plenty of other factors that contribute to cupper point of coffee.

4. Also Variability of "Cupper Points" except for "None" are much more compact and have outliers but it seems that for beans with No color, the trend is opposite and they have much wider distribution and no outliers. 

### One Numerical and one Catgorical variables: processing_method and number_of_bags

Making a bar plot for processing_method, we can see there are 'NA' values, 

```{r}
ggplot(coffee)+
  geom_bar(aes(processing_method))+
  labs(x='Method')+
  coord_flip()
```

### Removing NA values

We can remove them by

```{r}
coffee2<-coffee %>% filter(processing_method!='NA')
```

We can make a density graph to show the relationship between the number of bags tested and the processing method used for them. We have five processing methods.

```{r out.width = "100%"}
ggplot(coffee2,aes( x = number_of_bags,fill=processing_method) ) +
  geom_density(alpha = 0.4)+
  labs(title='Bags distribution by Processing Method',x="No. of bags",fill="Method")+
  scale_fill_brewer(palette="Paired")+
  theme_light()
```

The density plot tells us that the 'Other','Pulped natural/honey' and 'Natural/Dry' Methods have the most wide range of number of bags while the most frequent methods used were 'Washed/Wet' and 'Semi-washed/Semi-pulped' as it is evident by the two peaks.

We can further observe this relationship by calculating mean number of bags per processing method, which gives us

```{r }
coffee2%>% group_by(processing_method)%>%
  summarize(avgbags=round(mean(number_of_bags),2))
```

So expanding our observation, on average pulped natural/honey method was used the most and in the density chart we can see that while this method doesn't have apparent peaks, it has mini peaks that are more spread out meaning it was used more frequently and for more number of bags, hence the higher average.<br/>
While Semi Washed/Semi-pulped' method does have peaks,it is not spread out.


For 1 Numerical and 1 Categorical variable pair, I will use Processing Method and Total Cup Points:

1. Exploring variables

```{r}
glimpse(coffee_ratings$total_cup_points)
glimpse(coffee_ratings$processing_method)
```

2. For each processing method, we wanted to compute the centrality and spread. Let’s give it a try.

```{r}
na.omit(coffee_ratings) %>%
    group_by(processing_method) %>%
    summarize(mean_cup_points = mean(total_cup_points), sd_cup_points = sd(total_cup_points))
```

We can clearly see that the spread of Other processing method is quite higher than the all other given processing methods of coffee.

3.To visualize the relationship between these two variables we will use Boxplot.

```{r}
ggplot(na.omit(coffee_ratings),aes(processing_method,total_cup_points,color = processing_method))+
  geom_boxplot(show.legend = FALSE)+
  geom_jitter(alpha = 0.3,show.legend = FALSE)+
  theme_minimal()+
  labs(title = "Spread of cup points based on processing method")+
  xlab("Processing Method")+
  ylab("Total cup Points")
```

4. We can now analyze the centrality and spread of a continuous variable, both univariately and bivariately with respect to a categorical variable. 

### For 1 Numerical and 1 Categorical variable pair, I I am using Species and Flavor:

1. To visualize the relationship between these two variables we will use Boxplot.

```{r}
table1<-data.frame(table(coffee_ratings$flavor,coffee_ratings$species))

colnames(table1)<-c('flavor','species', 'Count')
head(table1,5)
```

```{r}
coffee_ratings_clean_flavor <- coffee_ratings %>% 
  drop_na(flavor)
```

```{r warning=FALSE}
ggplot(coffee_ratings,aes(flavor,species,color= species)) + xlim(5,10) +
  geom_boxplot( size=1.3,
                outlier.shape = 1,
                outlier.color = "black",
                outlier.size  = 2)+
labs(x="flavor",y="species",title= "Relationship between Species & Flavor") +
  theme_minimal()
```

We can clearly seen from above that the Arabica have a sweet flavor then Robusta.

### bivariate analysis between categorical and numerical variable 

For our bivariate analysis we will be using grading date and total cup points variables.

1. First we will need to calculate year from grading year to analyse it.

```{r}
coffee_ratings$'year' <-  (as.factor(str_sub(trimws(coffee_ratings$grading_date,"r"), -4,-1)))
```

```{r warning=FALSE}
coffee_ratings %>% 
  ggplot(aes(x=year, y=total_cup_points)) + 
  geom_jitter(height=0, alpha=0.25, size=0.5, width=0.3) +
  geom_boxplot(alpha=0, aes(colour =year))+ylim(70, 90)
```

```{r message=FALSE,warning=FALSE}
ggplot(coffee_ratings, aes(x = total_cup_points, y = year, fill = year)) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none") + xlim(75, 90)+
  labs(x="Cup Points",y="Year",title= "Yearly distribution of cup points")
```

> As can be seen from the graph for year 2010 has the most spread of cup points and is bimodal distribution. For year 2011 to 2017 the peak is concentrated between 82-84 cup points and the distribution is unimodal. But for year 2018 the distribution is again bimodal. 
